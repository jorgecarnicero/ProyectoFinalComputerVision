{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e382681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np, matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import glob\n",
    "from ultralytics import YOLO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a3fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames):\n",
    "    return [cv2.imread(filename) for filename in filenames]\n",
    "\n",
    "# TODO Complete the method, use every argument\n",
    "def show_image(img: np.array, img_name: str = \"Image\"):\n",
    "    cv2.imshow(img_name, img) \n",
    "    cv2.waitKey(0)  #\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# TODO Complete the method, use every argument\n",
    "def write_image(output_folder: str, img_name: str, img: np.array):\n",
    "    img_path = os.path.join(output_folder, img_name)  \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    cv2.imwrite(img_path, img)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d365e9f",
   "metadata": {},
   "source": [
    "# Ball segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "265efa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Values ---\n",
      "green_lower = np.array([29, 80, 100])\n",
      "green_upper = np.array([90, 255, 255])\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "\n",
    "cv2.namedWindow('Calibrator')\n",
    "\n",
    "\n",
    "cv2.createTrackbar('H Min', 'Calibrator', 29, 179, nothing) \n",
    "cv2.createTrackbar('H Max', 'Calibrator', 90, 179, nothing) \n",
    "cv2.createTrackbar('S Min', 'Calibrator', 80, 255, nothing) \n",
    "cv2.createTrackbar('S Max', 'Calibrator', 255, 255, nothing)\n",
    "cv2.createTrackbar('V Min', 'Calibrator', 100, 255, nothing)\n",
    "cv2.createTrackbar('V Max', 'Calibrator', 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "   \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "    \n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.6, fy=0.6)\n",
    "    \n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    h_min = cv2.getTrackbarPos('H Min', 'Calibrator')\n",
    "    h_max = cv2.getTrackbarPos('H Max', 'Calibrator')\n",
    "    s_min = cv2.getTrackbarPos('S Min', 'Calibrator')\n",
    "    s_max = cv2.getTrackbarPos('S Max', 'Calibrator')\n",
    "    v_min = cv2.getTrackbarPos('V Min', 'Calibrator')\n",
    "    v_max = cv2.getTrackbarPos('V Max', 'Calibrator')\n",
    "    \n",
    "    lower_green = np.array([h_min, s_min, v_min])\n",
    "    upper_green = np.array([h_max, s_max, v_max])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    \n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    mask_bgr = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "    stacked = np.hstack([frame, mask_bgr, result])\n",
    "    \n",
    "    cv2.imshow('Calibrator', stacked)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        print(\"\\n--- Final Values ---\")\n",
    "        print(f\"green_lower = np.array([{h_min}, {s_min}, {v_min}])\")\n",
    "        print(f\"green_upper = np.array([{h_max}, {s_max}, {v_max}])\")\n",
    "        print(\"---------------------------\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a1f9d",
   "metadata": {},
   "source": [
    "## Ball segmentation with body lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7465ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "model = YOLO('yolov8n-pose.pt') \n",
    "\n",
    "# COLOR VALUES (Ensure they are well calibrated for your video)\n",
    "# green_lower = np.array([35, 97, 234])\n",
    "# green_upper = np.array([45, 196, 255])\n",
    "\n",
    "# 2. YOUR CALIBRATED VALUES (The ones you sent me)\n",
    "green_lower = np.array([37, 61, 100])\n",
    "green_upper = np.array([54, 138, 226])\n",
    "\n",
    "# SUBTRACTOR\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "def get_player_zone_pro(results, shape_img):\n",
    "    h, w = shape_img[:2]\n",
    "    zone_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    waist_y = None\n",
    "    \n",
    "    if not results or len(results) == 0 or results[0].keypoints is None:\n",
    "        return zone_mask, None, None\n",
    "\n",
    "    points = results[0].keypoints.xy[0].cpu().numpy()\n",
    "    valid_points = points[np.all(points > 0, axis=1)]\n",
    "    \n",
    "    # Waist\n",
    "    hips = []\n",
    "    if points[11][1] > 0: hips.append(points[11][1])\n",
    "    if points[12][1] > 0: hips.append(points[12][1])\n",
    "    if len(hips) > 0: waist_y = int(sum(hips) / len(hips))\n",
    "\n",
    "    # Zone\n",
    "    if len(valid_points) > 0:\n",
    "        min_y, max_y = np.min(valid_points[:, 1]), np.max(valid_points[:, 1])\n",
    "        min_x, max_x = np.min(valid_points[:, 0]), np.max(valid_points[:, 0])\n",
    "        cx, cy = int((min_x + max_x) / 2), int((min_y + max_y) / 2)\n",
    "        \n",
    "        height = max_y - min_y\n",
    "        radius = int(height * 1.2) if height > 0 else 100 # Slightly more generous radius\n",
    "        cv2.circle(zone_mask, (cx, cy), radius, 255, -1)\n",
    "        return zone_mask, (cx, cy, radius), waist_y\n",
    "    \n",
    "    return zone_mask, None, None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        continue\n",
    "    \n",
    "    frame_visual = frame.copy()\n",
    "\n",
    "    # --- IMPROVEMENT 1: PRE-SMOOTHING (Reduces sensor noise) ---\n",
    "    # This eliminates random dots before MOG2 sees them\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "\n",
    "    # 1. YOLOV8 ZONE\n",
    "    results = model(frame, conf=0.5, max_det=1, verbose=False)\n",
    "    zone_mask, zone_info, waist_y = get_player_zone_pro(results, frame.shape)\n",
    "\n",
    "    # 2. MASKS\n",
    "    hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV) # Use smoothed frame\n",
    "    mask_color = cv2.inRange(hsv, green_lower, green_upper)\n",
    "\n",
    "    movement_mask = fgbg.apply(frame_blur) # Use smoothed frame\n",
    "\n",
    "    # --- IMPROVEMENT 2: SMART MORPHOLOGY ---\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    \n",
    "    # A) OPENING: First erodes (deletes small noise) and then dilates (recovers size)\n",
    "    # This eliminates sparks of 1 or 2 pixels that are not the ball\n",
    "    movement_mask = cv2.morphologyEx(movement_mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # B) SOFT DILATE: Now we fatten it a bit to join the ball if it is fragmented\n",
    "    # Lowered iterations from 3 to 2 so the box is tighter to the real ball\n",
    "    movement_mask = cv2.dilate(movement_mask, kernel, iterations=2)\n",
    "    \n",
    "    # 3. FUSION\n",
    "    potential_ball = cv2.bitwise_and(mask_color, mask_color, mask=movement_mask)\n",
    "    mask_final = cv2.bitwise_and(potential_ball, potential_ball, mask=zone_mask)\n",
    "\n",
    "    # 4. CONTOUR FILTERING\n",
    "    contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        # --- IMPROVEMENT 3: GEOMETRY FILTERS ---\n",
    "        # A) Area Filter: Raised from 1 to 15 (now 100). A real ball will never be 1 pixel.\n",
    "        if area > 100: \n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # B) Aspect Ratio Filter\n",
    "            # A ball is square (1:1). If it is a long line (noise), w will be much larger than h.\n",
    "            aspect_ratio = float(w) / h\n",
    "            \n",
    "            # We accept if it is \"almost\" square (between 0.5 and 1.5)\n",
    "            if 0.5 < aspect_ratio < 1.5:\n",
    "                cv2.rectangle(frame_visual, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                # We put the area so you can see how much it really occupies\n",
    "                cv2.putText(frame_visual, f\"BALL {int(area)}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # --- DRAWINGS ---\n",
    "    if zone_info:\n",
    "        cx, cy, r = zone_info\n",
    "        cv2.circle(frame_visual, (cx, cy), r, (255, 0, 0), 2)\n",
    "    \n",
    "    if waist_y:\n",
    "        cv2.line(frame_visual, (0, waist_y), (frame.shape[1], waist_y), (0, 255, 255), 2)\n",
    "\n",
    "    # Montage\n",
    "    mask_final_bgr = cv2.cvtColor(mask_final, cv2.COLOR_GRAY2BGR)\n",
    "    dual_view = np.hstack([frame_visual, mask_final_bgr])\n",
    "    dual_view = cv2.resize(dual_view, (0,0), fx=0.8, fy=0.8)\n",
    "\n",
    "    cv2.imshow('Precise Debug', dual_view)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45cf92f",
   "metadata": {},
   "source": [
    "# Bounce Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9bf8c6",
   "metadata": {},
   "source": [
    "## Without V-SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c604db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\") # <--- YOUR VIDEO\n",
    "model = YOLO('yolov8n-pose.pt') \n",
    "\n",
    "# YOUR COLOR VALUES\n",
    "# green_lower = np.array([35, 97, 234])\n",
    "# green_upper = np.array([45, 196, 255])\n",
    "# 2. YOUR CALIBRATED VALUES (The ones you sent me)\n",
    "green_lower = np.array([37, 61, 100])\n",
    "green_upper = np.array([54, 138, 226])\n",
    "# BACKGROUND SUBTRACTOR\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# VARIABLES\n",
    "prev_ball_y = None  \n",
    "photo_taken = False    \n",
    "cooldown_frames = 0     \n",
    "\n",
    "def get_player_zone_pro(results, shape_img):\n",
    "    h, w = shape_img[:2]\n",
    "    zone_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    waist_y = None \n",
    "    ground_y = None\n",
    "    \n",
    "    if not results or len(results) == 0 or results[0].keypoints is None:\n",
    "        return zone_mask, None, None, None\n",
    "\n",
    "    points = results[0].keypoints.xy[0].cpu().numpy()\n",
    "    valid_points = points[np.all(points > 0, axis=1)]\n",
    "    \n",
    "    # Waist\n",
    "    hips = []\n",
    "    if points[11][1] > 0: hips.append(points[11][1])\n",
    "    if points[12][1] > 0: hips.append(points[12][1])\n",
    "    if len(hips) > 0: waist_y = int(sum(hips) / len(hips))\n",
    "\n",
    "    # Ground (Ankles)\n",
    "    feet = []\n",
    "    if points[15][1] > 0: feet.append(points[15][1])\n",
    "    if points[16][1] > 0: feet.append(points[16][1])\n",
    "    \n",
    "    if len(feet) > 0:\n",
    "        ground_y = int(max(feet) - 20) \n",
    "    elif waist_y:\n",
    "        ground_y = int(waist_y * 1.6)\n",
    "\n",
    "    # Zone\n",
    "    if len(valid_points) > 0:\n",
    "        min_y, max_y = np.min(valid_points[:, 1]), np.max(valid_points[:, 1])\n",
    "        min_x, max_x = np.min(valid_points[:, 0]), np.max(valid_points[:, 0])\n",
    "        cx, cy = int((min_x + max_x) / 2), int((min_y + max_y) / 2)\n",
    "        height = max_y - min_y\n",
    "        radius = int(height * 1.2) if height > 0 else 100\n",
    "        cv2.circle(zone_mask, (cx, cy), radius, 255, -1)\n",
    "        return zone_mask, (cx, cy, radius), waist_y, ground_y\n",
    "    \n",
    "    return zone_mask, None, None, None\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        prev_ball_y = None \n",
    "        photo_taken = False\n",
    "        continue\n",
    "    \n",
    "    frame_visual = frame.copy()\n",
    "\n",
    "    # --- STEP 1: PLAYER DETECTION ---\n",
    "    results = model(frame, conf=0.5, max_det=1, verbose=False)\n",
    "    zone_mask, zone_info, waist_y, ground_y = get_player_zone_pro(results, frame.shape)\n",
    "\n",
    "    # --- STEP 2: IMPROVED BALL DETECTION (SNIPER MODE) ---\n",
    "    \n",
    "    # 1. SMOOTHING (Kills camera noise)\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    \n",
    "    # 2. MASKS (Using smoothed frame)\n",
    "    hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "    mask_color = cv2.inRange(hsv, green_lower, green_upper)\n",
    "\n",
    "    movement_mask = fgbg.apply(frame_blur)\n",
    "    \n",
    "    # 3. SMART MORPHOLOGY\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    # First delete small noise (Opening)\n",
    "    movement_mask = cv2.morphologyEx(movement_mask, cv2.MORPH_OPEN, kernel)\n",
    "    # Then fatten valid objects a bit (Dilate x2 instead of x3 for more precision)\n",
    "    movement_mask = cv2.dilate(movement_mask, kernel, iterations=2)\n",
    "    \n",
    "    # Fusion\n",
    "    potential_ball = cv2.bitwise_and(mask_color, mask_color, mask=movement_mask)\n",
    "    mask_final = cv2.bitwise_and(potential_ball, potential_ball, mask=zone_mask)\n",
    "\n",
    "    # --- STEP 3: GEOMETRIC FILTERING ---\n",
    "    contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    curr_ball_y = None \n",
    "    cx_ball = 0\n",
    "    max_area = 0\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        \n",
    "        # AREA FILTER (Raised to 15 (80 in logic) to ignore sparks)\n",
    "        if area > 80: \n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            \n",
    "            # SHAPE FILTER (Aspect Ratio)\n",
    "            # We only accept if it is more or less square/round (0.5 to 1.5)\n",
    "            # This eliminates elongated lines or noise\n",
    "            aspect_ratio = float(w) / h\n",
    "            \n",
    "            if 0.5 < aspect_ratio < 1.5:\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    curr_ball_y = y + h//2\n",
    "                    cx_ball = x + w//2\n",
    "                    \n",
    "                    # Draw validated ball\n",
    "                    cv2.rectangle(frame_visual, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame_visual, f\"BALL {int(area)}\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # --- STEP 4: BOUNCE LOGIC (UP -> DOWN) ---\n",
    "    # (This part is identical to your original code, only uses cleaner data from above)\n",
    "    if curr_ball_y is not None and prev_ball_y is not None and ground_y is not None:\n",
    "        \n",
    "        # 1. Was it ABOVE before?\n",
    "        was_above = prev_ball_y < ground_y\n",
    "        \n",
    "        # 2. Is it DOWN now?\n",
    "        is_below = curr_ball_y >= ground_y\n",
    "        \n",
    "        # CROSSING CONDITION\n",
    "        if was_above and is_below and not photo_taken:\n",
    "            \n",
    "            # --- PHOTO ---\n",
    "            impact_photo = frame.copy()\n",
    "            if ground_y: cv2.line(impact_photo, (0, ground_y), (frame.shape[1], ground_y), (0, 0, 255), 3)\n",
    "            cv2.circle(impact_photo, (cx_ball, curr_ball_y), 15, (0, 255, 255), -1)\n",
    "            cv2.putText(impact_photo, \"BOUNCE DETECTED (LINE CROSSING)\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow(\"BOUNCE EVIDENCE PHOTO\", impact_photo)\n",
    "            print(\"Photo taken! Bounce confirmed.\")\n",
    "            \n",
    "            photo_taken = True\n",
    "            cooldown_frames = 20 \n",
    "\n",
    "    # Update memory\n",
    "    if curr_ball_y is not None:\n",
    "        prev_ball_y = curr_ball_y\n",
    "        \n",
    "    # Reset photo\n",
    "    if photo_taken:\n",
    "        cooldown_frames -= 1\n",
    "        if cooldown_frames <= 0:\n",
    "            photo_taken = False\n",
    "\n",
    "    # --- VISUALIZATION ---\n",
    "    if zone_info:\n",
    "        cx, cy, r = zone_info\n",
    "        cv2.circle(frame_visual, (cx, cy), r, (255, 0, 0), 2)\n",
    "\n",
    "    if waist_y is not None:\n",
    "        cv2.line(frame_visual, (0, waist_y), (frame.shape[1], waist_y), (0, 255, 255), 2)\n",
    "\n",
    "    if ground_y is not None:\n",
    "        cv2.line(frame_visual, (0, ground_y), (frame.shape[1], ground_y), (0, 0, 255), 2)\n",
    "        cv2.putText(frame_visual, \"GROUND TRIGGER\", (10, ground_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    # MONTAGE\n",
    "    mask_final_bgr = cv2.cvtColor(mask_final, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(mask_final_bgr, \"FILTERED MASK\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    dual_view = np.hstack([frame_visual, mask_final_bgr])\n",
    "    dual_view = cv2.resize(dual_view, (0,0), fx=0.8, fy=0.8)\n",
    "\n",
    "    cv2.imshow('Precise Padel Detector', dual_view)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd7852",
   "metadata": {},
   "source": [
    "## V-SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1daaed7",
   "metadata": {},
   "source": [
    "### With Optical Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ad0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "model = YOLO('yolov8n-pose.pt') \n",
    "\n",
    "# COLORS\n",
    "# green_lower = np.array([35, 97, 234])\n",
    "# green_upper = np.array([45, 196, 255])\n",
    "\n",
    "# 2. YOUR CALIBRATED VALUES (The ones you sent me)\n",
    "# green_lower = np.array([37, 61, 100])\n",
    "# green_upper = np.array([54, 138, 226])\n",
    "\n",
    "green_lower = np.array([37, 61, 100])\n",
    "green_upper = np.array([54, 138, 226])\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# --- OPTICAL FLOW VARIABLES (VISUAL) ---\n",
    "# Parameters for Lucas-Kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "visual_trail = deque(maxlen=20) \n",
    "p0 = None\n",
    "old_gray = None\n",
    "\n",
    "# --- MEMORY VARIABLES (VISUAL PERMANENCE) ---\n",
    "frames_without_detection = 0    \n",
    "MAX_LOST_MEMORY = 10    \n",
    "\n",
    "# --- \"V-SHAPE\" BOUNCE LOGIC VARIABLES (PHYSICS) ---\n",
    "# States: 0 = Looking for drop, 1 = Verifying rise\n",
    "bounce_state = 0 \n",
    "prev_ball_y = None  \n",
    "candidate_frame = None      \n",
    "min_y_registered = 0     \n",
    "verification_frames = 0  \n",
    "photo_confirmed = False     \n",
    "display_photo_timer = 0     \n",
    "\n",
    "def get_player_zone_pro(results, shape_img):\n",
    "    h, w = shape_img[:2]\n",
    "    zone_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    waist_y = None \n",
    "    ground_y = None\n",
    "    \n",
    "    if not results or len(results) == 0 or results[0].keypoints is None:\n",
    "        return zone_mask, None, None, None\n",
    "\n",
    "    points = results[0].keypoints.xy[0].cpu().numpy()\n",
    "    valid_points = points[np.all(points > 0, axis=1)]\n",
    "    \n",
    "    if len(valid_points) > 0:\n",
    "        # 1. WAIST\n",
    "        hips = []\n",
    "        if points[11][1] > 0: hips.append(points[11][1])\n",
    "        if points[12][1] > 0: hips.append(points[12][1])\n",
    "        if len(hips) > 0: waist_y = int(sum(hips) / len(hips))\n",
    "\n",
    "        # 2. GROUND (ANKLES)\n",
    "        feet = []\n",
    "        if points[15][1] > 0: feet.append(points[15][1])\n",
    "        if points[16][1] > 0: feet.append(points[16][1])\n",
    "        if len(feet) > 0:\n",
    "            ground_y = int(max(feet) - 20) \n",
    "        elif waist_y:\n",
    "            ground_y = int(waist_y * 1.6)\n",
    "\n",
    "        # 3. PLAYER ZONE\n",
    "        min_y, max_y = np.min(valid_points[:, 1]), np.max(valid_points[:, 1])\n",
    "        min_x, max_x = np.min(valid_points[:, 0]), np.max(valid_points[:, 0])\n",
    "        cx, cy = int((min_x + max_x) / 2), int((min_y + max_y) / 2)\n",
    "        height = max_y - min_y\n",
    "        radius = int(height * 1.2) if height > 0 else 100\n",
    "        cv2.circle(zone_mask, (cx, cy), radius, 255, -1)\n",
    "        return zone_mask, (cx, cy, radius), waist_y, ground_y\n",
    "    \n",
    "    return zone_mask, None, None, None\n",
    "\n",
    "# --- LOOP ---\n",
    "ret, old_frame = cap.read()\n",
    "if not ret: exit()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        # Total Reset\n",
    "        prev_ball_y = None \n",
    "        bounce_state = 0\n",
    "        candidate_frame = None\n",
    "        photo_confirmed = False\n",
    "        \n",
    "        # Graphics Reset\n",
    "        visual_trail.clear()\n",
    "        p0 = None\n",
    "        frames_without_detection = 0\n",
    "        continue\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Necessary for Optical Flow\n",
    "    frame_visual = frame.copy()\n",
    "\n",
    "    # 1. PLAYER INFO (WAIST + GROUND)\n",
    "    results = model(frame, conf=0.5, max_det=1, verbose=False)\n",
    "    zone_mask, zone_info, waist_y, ground_y = get_player_zone_pro(results, frame.shape)\n",
    "\n",
    "    # 2. DETECTION (SNIPER)\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "    mask_color = cv2.inRange(hsv, green_lower, green_upper)\n",
    "    mask_mov = fgbg.apply(frame_blur)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask_mov = cv2.morphologyEx(mask_mov, cv2.MORPH_OPEN, kernel)\n",
    "    mask_mov = cv2.dilate(mask_mov, kernel, iterations=2)\n",
    "    \n",
    "    potential_ball = cv2.bitwise_and(mask_color, mask_color, mask=mask_mov)\n",
    "    mask_final = cv2.bitwise_and(potential_ball, potential_ball, mask=zone_mask)\n",
    "\n",
    "    # 3. FIND BALL\n",
    "    contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    curr_ball_y = None \n",
    "    cx_ball = 0\n",
    "    max_area = 0\n",
    "    detected_ball_center = None \n",
    "    ball_detected_this_frame = False \n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 80: # Area Filter\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.5 < aspect_ratio < 1.5: # Shape Filter\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    curr_ball_y = y + h//2\n",
    "                    cx_ball = x + w//2\n",
    "                    \n",
    "                    # Save data for Optical Flow\n",
    "                    detected_ball_center = np.array([[[cx_ball, curr_ball_y]]], dtype=np.float32)\n",
    "                    ball_detected_this_frame = True\n",
    "\n",
    "                    # Base drawing (Green Box)\n",
    "                    cv2.rectangle(frame_visual, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame_visual, \"BALL\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # --- 4. OPTICAL FLOW (GRAPHICS ONLY) ---\n",
    "    new_flow_point = None\n",
    "    if p0 is not None:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        if p1 is not None and st[0] == 1: new_flow_point = p1\n",
    "        else: new_flow_point = None\n",
    "\n",
    "    if ball_detected_this_frame:\n",
    "        # A) Real ball found: Reset flow to real position\n",
    "        frames_without_detection = 0\n",
    "        p0 = detected_ball_center \n",
    "        visual_trail.append((cx_ball, curr_ball_y))\n",
    "        # Orange Ball (Real)\n",
    "        cv2.circle(frame_visual, (cx_ball, curr_ball_y), 5, (0, 165, 255), -1) \n",
    "    \n",
    "    elif new_flow_point is not None and frames_without_detection < MAX_LOST_MEMORY:\n",
    "        # B) No real ball, but using visual memory\n",
    "        frames_without_detection += 1\n",
    "        a, b = new_flow_point[0].ravel()\n",
    "        p0 = new_flow_point.reshape(-1, 1, 2)\n",
    "        visual_trail.append((int(a), int(b)))\n",
    "        # Orange Ball (Ghost)\n",
    "        cv2.circle(frame_visual, (int(a), int(b)), 4, (0, 100, 255), -1) \n",
    "    else:\n",
    "        # C) Total loss\n",
    "        frames_without_detection = 0\n",
    "        visual_trail.clear()\n",
    "        p0 = None\n",
    "\n",
    "    # DRAW THE SNAKE (TRAIL)\n",
    "    for i in range(1, len(visual_trail)):\n",
    "        if visual_trail[i - 1] is None or visual_trail[i] is None: continue\n",
    "        thickness = int(np.sqrt(20 / float(len(visual_trail) - i + 1)) * 2)\n",
    "        cv2.line(frame_visual, visual_trail[i - 1], visual_trail[i], (0, 255, 255), thickness)\n",
    "\n",
    "\n",
    "    # --- 5. \"V-SHAPE\" BOUNCE LOGIC (DROP -> IMPACT -> RISE) ---\n",
    "    if curr_ball_y is not None and ground_y is not None:\n",
    "        \n",
    "        # STATE 0: LOOKING FOR IMPACT (DROP)\n",
    "        if bounce_state == 0:\n",
    "            if prev_ball_y is not None:\n",
    "                # Condition: Crossing line downwards\n",
    "                was_above = prev_ball_y < ground_y\n",
    "                is_below = curr_ball_y >= ground_y\n",
    "                \n",
    "                if was_above and is_below:\n",
    "                    # POSSIBLE BOUNCE!\n",
    "                    candidate_frame = frame.copy()\n",
    "                    \n",
    "                    # Draw references on candidate photo\n",
    "                    cv2.line(candidate_frame, (0, ground_y), (w, ground_y), (0, 0, 255), 2)\n",
    "                    cv2.circle(candidate_frame, (cx_ball, curr_ball_y), 15, (0, 255, 255), -1)\n",
    "                    \n",
    "                    # Change state\n",
    "                    bounce_state = 1\n",
    "                    min_y_registered = curr_ball_y\n",
    "                    verification_frames = 0\n",
    "                    print(\"Impact detected... Verifying rebound.\")\n",
    "\n",
    "        # STATE 1: VERIFYING REBOUND (RISE)\n",
    "        elif bounce_state == 1:\n",
    "            verification_frames += 1\n",
    "            \n",
    "            # Update lowest point touched\n",
    "            if curr_ball_y > min_y_registered:\n",
    "                min_y_registered = curr_ball_y\n",
    "            \n",
    "            # SUCCESS CRITERIA: Ball has risen X pixels from min point\n",
    "            REQUIRED_RISE_PIXELS = 15 \n",
    "            \n",
    "            if curr_ball_y < (min_y_registered - REQUIRED_RISE_PIXELS):\n",
    "                # CONFIRMED! It made the \"V\"\n",
    "                print(\"Rebound Confirmed!\")\n",
    "                cv2.putText(candidate_frame, \"BOUNCE CONFIRMED (V-SHAPE)\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                \n",
    "                photo_confirmed = True\n",
    "                display_photo_timer = 40 \n",
    "                bounce_state = 0 \n",
    "                \n",
    "            # FAILURE CRITERIA: Too much time passed and no rise\n",
    "            if verification_frames > 20:\n",
    "                print(\"False positive: Ball rolling.\")\n",
    "                bounce_state = 0\n",
    "                candidate_frame = None\n",
    "\n",
    "    # Update position memory\n",
    "    if curr_ball_y is not None:\n",
    "        prev_ball_y = curr_ball_y\n",
    "\n",
    "    # --- 6. FINAL VISUALIZATION (LINES ARE HERE) ---\n",
    "    # 1. Player Zone (Blue Circle)\n",
    "    if zone_info:\n",
    "        cx, cy, r = zone_info\n",
    "        cv2.circle(frame_visual, (cx, cy), r, (255, 0, 0), 2)\n",
    "    \n",
    "    # 2. Waist Line (Yellow)\n",
    "    if waist_y:\n",
    "        cv2.line(frame_visual, (0, waist_y), (frame.shape[1], waist_y), (0, 255, 255), 2)\n",
    "        cv2.putText(frame_visual, \"WAIST\", (10, waist_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    # 3. Ground Line (Red / Green)\n",
    "    if ground_y:\n",
    "        # Line turns GREEN if waiting for rebound (State 1)\n",
    "        ground_color = (0, 255, 0) if bounce_state == 1 else (0, 0, 255) \n",
    "        cv2.line(frame_visual, (0, ground_y), (frame.shape[1], ground_y), ground_color, 2)\n",
    "        cv2.putText(frame_visual, \"GROUND\", (10, ground_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, ground_color, 1)\n",
    "\n",
    "    # SHOW CONFIRMED PHOTO IF EXISTS\n",
    "    if photo_confirmed and candidate_frame is not None:\n",
    "        cv2.imshow(\"BOUNCE EVIDENCE PHOTO\", candidate_frame)\n",
    "        display_photo_timer -= 1\n",
    "        if display_photo_timer <= 0:\n",
    "            photo_confirmed = False\n",
    "\n",
    "    mask_bgr = cv2.cvtColor(mask_final, cv2.COLOR_GRAY2BGR)\n",
    "    dual_view = np.hstack([frame_visual, mask_bgr])\n",
    "    dual_view = cv2.resize(dual_view, (0,0), fx=0.8, fy=0.8)\n",
    "\n",
    "    cv2.imshow('Padel Final - Physics + Visuals', dual_view)\n",
    "    \n",
    "    old_gray = frame_gray.copy()\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ae0df",
   "metadata": {},
   "source": [
    "### With kalman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86eeb8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\Win\\ipykernel_31108\\438876912.py:153: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(pred_x), int(pred_y)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "\n",
    "# --- KALMAN FILTER CLASS ---\n",
    "class KalmanTracker:\n",
    "    def __init__(self):\n",
    "        # 4 dynamic params (x, y, dx, dy) + 2 measurement params (x, y)\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0],\n",
    "                                                  [0, 1, 0, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0],\n",
    "                                                 [0, 1, 0, 1],\n",
    "                                                 [0, 0, 1, 0],\n",
    "                                                 [0, 0, 0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "        self.kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.00003\n",
    "        self.kalman.errorCovPost = np.eye(4, dtype=np.float32) * 1\n",
    "\n",
    "    def predict(self):\n",
    "        prediction = self.kalman.predict()\n",
    "        return prediction[0], prediction[1]\n",
    "\n",
    "    def correct(self, x, y):\n",
    "        self.kalman.correct(np.array([[np.float32(x)], [np.float32(y)]]))\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "cap = cv2.VideoCapture(\"videos/video.mp4\")\n",
    "model = YOLO('yolov8n-pose.pt') \n",
    "\n",
    "# COLORS\n",
    "green_lower = np.array([37, 61, 100])\n",
    "green_upper = np.array([54, 138, 226])\n",
    "\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# --- VISUAL VARIABLES ---\n",
    "traza_visual = deque(maxlen=20) \n",
    "frames_sin_deteccion = 0    \n",
    "MAX_MEMORIA_PERDIDA = 10    \n",
    "\n",
    "# --- LOGIC VARIABLES ---\n",
    "estado_bote = 0 \n",
    "y_bola_anterior = None  \n",
    "frame_candidato = None      \n",
    "y_minimo_registrado = 0     \n",
    "frames_en_verificacion = 0  \n",
    "foto_confirmada = False     \n",
    "frames_display_foto = 0     \n",
    "\n",
    "# Initialize Kalman Tracker\n",
    "tracker = KalmanTracker()\n",
    "\n",
    "def obtener_zona_jugador_pro(results, shape_img):\n",
    "    h, w = shape_img[:2]\n",
    "    mask_zona = np.zeros((h, w), dtype=np.uint8)\n",
    "    y_cintura = None \n",
    "    y_suelo = None\n",
    "    \n",
    "    # --- FIX: Validación robusta para evitar crash si no hay detección ---\n",
    "    if not results: # Si la lista está vacía\n",
    "        return mask_zona, None, None, None\n",
    "        \n",
    "    # Verificar si hay keypoints detectados en el primer resultado\n",
    "    if not hasattr(results[0], 'keypoints') or results[0].keypoints is None:\n",
    "        return mask_zona, None, None, None\n",
    "\n",
    "    # Verificar si el tensor de keypoints tiene datos\n",
    "    if results[0].keypoints.xy.numel() == 0:\n",
    "        return mask_zona, None, None, None\n",
    "\n",
    "    # --- Fin validación ---\n",
    "\n",
    "    puntos = results[0].keypoints.xy[0].cpu().numpy()\n",
    "    \n",
    "    # Verificar si hay suficientes puntos detectados\n",
    "    if len(puntos) == 0:\n",
    "         return mask_zona, None, None, None\n",
    "\n",
    "    puntos_validos = puntos[np.all(puntos > 0, axis=1)]\n",
    "    \n",
    "    if len(puntos_validos) > 0:\n",
    "        caderas = []\n",
    "        if len(puntos) > 12: # Asegurar que existen los índices\n",
    "            if puntos[11][1] > 0: caderas.append(puntos[11][1])\n",
    "            if puntos[12][1] > 0: caderas.append(puntos[12][1])\n",
    "        if len(caderas) > 0: y_cintura = int(sum(caderas) / len(caderas))\n",
    "\n",
    "        pies = []\n",
    "        if len(puntos) > 16: # Asegurar índices\n",
    "            if puntos[15][1] > 0: pies.append(puntos[15][1])\n",
    "            if puntos[16][1] > 0: pies.append(puntos[16][1])\n",
    "        \n",
    "        if len(pies) > 0:\n",
    "            y_suelo = int(max(pies) - 20) \n",
    "        elif y_cintura:\n",
    "            y_suelo = int(y_cintura * 1.6)\n",
    "\n",
    "        min_y, max_y = np.min(puntos_validos[:, 1]), np.max(puntos_validos[:, 1])\n",
    "        min_x, max_x = np.min(puntos_validos[:, 0]), np.max(puntos_validos[:, 0])\n",
    "        cx, cy = int((min_x + max_x) / 2), int((min_y + max_y) / 2)\n",
    "        altura = max_y - min_y\n",
    "        radio = int(altura * 1.2) if altura > 0 else 100\n",
    "        cv2.circle(mask_zona, (cx, cy), radio, 255, -1)\n",
    "        return mask_zona, (cx, cy, radio), y_cintura, y_suelo\n",
    "    \n",
    "    return mask_zona, None, None, None\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: \n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        y_bola_anterior = None \n",
    "        estado_bote = 0\n",
    "        frame_candidato = None\n",
    "        foto_confirmada = False\n",
    "        traza_visual.clear()\n",
    "        frames_sin_deteccion = 0\n",
    "        tracker = KalmanTracker() # Reset Kalman\n",
    "        continue\n",
    "    \n",
    "    frame_visual = frame.copy()\n",
    "\n",
    "    # 1. PLAYER INFO\n",
    "    results = model(frame, conf=0.5, max_det=1, verbose=False)\n",
    "    mask_zona, info_zona, y_cintura, y_suelo = obtener_zona_jugador_pro(results, frame.shape)\n",
    "\n",
    "    # 2. DETECTION\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "    mask_color = cv2.inRange(hsv, green_lower, green_upper)\n",
    "    mask_mov = fgbg.apply(frame_blur)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask_mov = cv2.morphologyEx(mask_mov, cv2.MORPH_OPEN, kernel)\n",
    "    mask_mov = cv2.dilate(mask_mov, kernel, iterations=2)\n",
    "    \n",
    "    bola_potencial = cv2.bitwise_and(mask_color, mask_color, mask=mask_mov)\n",
    "    mask_final = cv2.bitwise_and(bola_potencial, bola_potencial, mask=mask_zona)\n",
    "\n",
    "    # 3. FIND BALL\n",
    "    contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    y_bola_actual = None \n",
    "    cx_bola = 0\n",
    "    max_area = 0\n",
    "    bola_detectada_este_frame = False \n",
    "\n",
    "    # --- KALMAN PREDICTION ---\n",
    "    pred_x, pred_y = tracker.predict()\n",
    "    pred_x, pred_y = int(pred_x), int(pred_y)\n",
    "\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 80: \n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.5 < aspect_ratio < 1.5: \n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    y_bola_actual = y + h//2\n",
    "                    cx_bola = x + w//2\n",
    "                    bola_detectada_este_frame = True\n",
    "\n",
    "                    # Update Kalman with REAL detection\n",
    "                    tracker.correct(cx_bola, y_bola_actual)\n",
    "\n",
    "                    cv2.rectangle(frame_visual, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.putText(frame_visual, \"BOLA\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # --- 4. HYBRID TRACKING LOGIC ---\n",
    "    if bola_detectada_este_frame:\n",
    "        # We have the real ball -> Use it and reset counters\n",
    "        frames_sin_deteccion = 0\n",
    "        traza_visual.append((cx_bola, y_bola_actual))\n",
    "        # Draw real ball (Orange)\n",
    "        cv2.circle(frame_visual, (cx_bola, y_bola_actual), 5, (0, 165, 255), -1) \n",
    "    \n",
    "    else:\n",
    "        # Ball NOT detected -> Check if we can use Kalman prediction\n",
    "        frames_sin_deteccion += 1\n",
    "        \n",
    "        # Only trust prediction if ball hasn't been lost for too long\n",
    "        if frames_sin_deteccion < MAX_MEMORIA_PERDIDA:\n",
    "            # Use PREDICTION as the actual ball position\n",
    "            cx_bola = pred_x\n",
    "            y_bola_actual = pred_y\n",
    "            \n",
    "            # Add ghost point to trace\n",
    "            traza_visual.append((pred_x, pred_y))\n",
    "            \n",
    "            # Draw ghost ball (Yellow/Cyan to differentiate)\n",
    "            cv2.circle(frame_visual, (pred_x, pred_y), 4, (255, 255, 0), -1) \n",
    "            cv2.putText(frame_visual, \"PREDICCION\", (pred_x + 5, pred_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)\n",
    "        else:\n",
    "            # Lost for too long -> Stop tracking\n",
    "            y_bola_actual = None \n",
    "            traza_visual.clear()\n",
    "\n",
    "    # Draw Trace\n",
    "    for i in range(1, len(traza_visual)):\n",
    "        if traza_visual[i - 1] is None or traza_visual[i] is None: continue\n",
    "        thickness = int(np.sqrt(20 / float(len(traza_visual) - i + 1)) * 2)\n",
    "        cv2.line(frame_visual, traza_visual[i - 1], traza_visual[i], (0, 255, 255), thickness)\n",
    "\n",
    "\n",
    "    # --- 5. PHYSICS LOGIC (BOTE \"EN V\") ---\n",
    "    if y_bola_actual is not None and y_suelo is not None:\n",
    "        \n",
    "        # STATE 0: WAITING FOR IMPACT\n",
    "        if estado_bote == 0:\n",
    "            if y_bola_anterior is not None:\n",
    "                estaba_arriba = y_bola_anterior < y_suelo\n",
    "                esta_abajo = y_bola_actual >= y_suelo\n",
    "                \n",
    "                if estaba_arriba and esta_abajo:\n",
    "                    frame_candidato = frame.copy()\n",
    "                    cv2.line(frame_candidato, (0, y_suelo), (w, y_suelo), (0, 0, 255), 2)\n",
    "                    cv2.circle(frame_candidato, (cx_bola, y_bola_actual), 15, (0, 255, 255), -1)\n",
    "                    \n",
    "                    estado_bote = 1\n",
    "                    y_minimo_registrado = y_bola_actual\n",
    "                    frames_en_verificacion = 0\n",
    "                    print(\"Impacto detectado... Verificando rebote.\")\n",
    "\n",
    "        # STATE 1: VERIFYING REBOUND\n",
    "        elif estado_bote == 1:\n",
    "            frames_en_verificacion += 1\n",
    "            \n",
    "            if y_bola_actual > y_minimo_registrado:\n",
    "                y_minimo_registrado = y_bola_actual\n",
    "            \n",
    "            PIXELES_SUBIDA_NECESARIOS = 15 \n",
    "            \n",
    "            if y_bola_actual < (y_minimo_registrado - PIXELES_SUBIDA_NECESARIOS):\n",
    "                print(\"¡Rebote Confirmado!\")\n",
    "                cv2.putText(frame_candidato, \"BOTE CONFIRMADO (V-SHAPE)\", (50, 50), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                \n",
    "                foto_confirmada = True\n",
    "                frames_display_foto = 40 \n",
    "                estado_bote = 0 \n",
    "                \n",
    "            if frames_en_verificacion > 20:\n",
    "                print(\"Falso positivo: Bola rodando.\")\n",
    "                estado_bote = 0\n",
    "                frame_candidato = None\n",
    "\n",
    "    if y_bola_actual is not None:\n",
    "        y_bola_anterior = y_bola_actual\n",
    "\n",
    "    # --- 6. VISUALIZATION ---\n",
    "    if info_zona:\n",
    "        cx, cy, r = info_zona\n",
    "        cv2.circle(frame_visual, (cx, cy), r, (255, 0, 0), 2)\n",
    "    \n",
    "    if y_cintura:\n",
    "        cv2.line(frame_visual, (0, y_cintura), (frame.shape[1], y_cintura), (0, 255, 255), 2)\n",
    "        cv2.putText(frame_visual, \"CINTURA\", (10, y_cintura - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "\n",
    "    if y_suelo:\n",
    "        color_suelo = (0, 255, 0) if estado_bote == 1 else (0, 0, 255) \n",
    "        cv2.line(frame_visual, (0, y_suelo), (frame.shape[1], y_suelo), color_suelo, 2)\n",
    "        cv2.putText(frame_visual, \"SUELO\", (10, y_suelo - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_suelo, 1)\n",
    "\n",
    "    if foto_confirmada and frame_candidato is not None:\n",
    "        cv2.imshow(\"FOTO EVIDENCIA BOTE\", frame_candidato)\n",
    "        frames_display_foto -= 1\n",
    "        if frames_display_foto <= 0:\n",
    "            foto_confirmada = False\n",
    "\n",
    "    mask_bgr = cv2.cvtColor(mask_final, cv2.COLOR_GRAY2BGR)\n",
    "    vista_doble = np.hstack([frame_visual, mask_bgr])\n",
    "    vista_doble = cv2.resize(vista_doble, (0,0), fx=0.8, fy=0.8)\n",
    "\n",
    "    cv2.imshow('Padel Final - Hybrid Tracking', vista_doble)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88cb73",
   "metadata": {},
   "source": [
    "# Hit Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "222141ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "[INFO] ⚠️ No GPU detected. TensorRT functionality disabled. Will attempt CPU fallback.\n",
      "------------------------------------------------\n",
      "[INFO] FILE Mode (Sequential Reading)\n",
      "[INFO] Loading standard model 'yolov8n-pose.pt'...\n",
      "[SUCCESS] Model .pt loaded on CPU (Expect lower FPS).\n",
      "[INFO] RESIZE ON (1280px). TensorRT Skip=3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\Win\\ipykernel_31108\\102369893.py:286: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(raw_pred_x), int(raw_pred_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SERVE DETECTED >> Kalman Accel: 40.0 | Flow Vel: 17.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import deque\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from threading import Thread\n",
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# 0. POWER CHECK\n",
    "# ==========================================\n",
    "print(\"------------------------------------------------\")\n",
    "has_gpu = torch.cuda.is_available()\n",
    "if has_gpu:\n",
    "    print(f\"[INFO] ✅ NVIDIA GPU DETECTED: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[INFO] ⚠️ No GPU detected. TensorRT functionality disabled. Will attempt CPU fallback.\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. CAMERA STREAM CLASS (THREADED)\n",
    "# ==========================================\n",
    "class CameraStream:\n",
    "    def __init__(self, src=0):\n",
    "        self.stream = cv2.VideoCapture(src)\n",
    "        if src == 0 or (isinstance(src, str) and src.isdigit()):\n",
    "            # Request max quality (we resize later for performance)\n",
    "            self.stream.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "            self.stream.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "            self.stream.set(cv2.CAP_PROP_FPS, 60) \n",
    "        (self.ret, self.frame) = self.stream.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.update, args=(), daemon=True).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.stopped: return\n",
    "            (self.ret, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        return self.ret, self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.stream.release()\n",
    "\n",
    "# ==========================================\n",
    "# 2. KALMAN FILTER (PHYSICS ENGINE)\n",
    "# ==========================================\n",
    "class KalmanTracker:\n",
    "    def __init__(self):\n",
    "        self.kalman = cv2.KalmanFilter(4, 2)\n",
    "        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "        self.kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "        self.kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.00003\n",
    "        self.kalman.errorCovPost = np.eye(4, dtype=np.float32) * 1\n",
    "\n",
    "    def predict(self):\n",
    "        prediction = self.kalman.predict()\n",
    "        return prediction[0], prediction[1]\n",
    "\n",
    "    def correct(self, x, y):\n",
    "        self.kalman.correct(np.array([[np.float32(x)], [np.float32(y)]]))\n",
    "\n",
    "# ==========================================\n",
    "# 3. SYSTEM CONFIGURATION\n",
    "# ==========================================\n",
    "video_path = \"videos/video.mp4\" \n",
    "# video_path = 0\n",
    "\n",
    "if video_path == 0 or (isinstance(video_path, str) and video_path.isdigit()):\n",
    "    cap = CameraStream(video_path).start()\n",
    "    is_live = True\n",
    "    print(\"[INFO] LIVE CAMERA Mode (Threading ON)\")\n",
    "else:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    is_live = False\n",
    "    print(\"[INFO] FILE Mode (Sequential Reading)\")\n",
    "\n",
    "# --- LOAD AI MODEL ---\n",
    "model_engine_path = 'yolov8n-pose.engine'\n",
    "model_pt_path = 'yolov8n-pose.pt'\n",
    "run_device = 0 # Por defecto intentamos GPU\n",
    "model_loaded = False\n",
    "\n",
    "# 1. Try to load engine \n",
    "if has_gpu and os.path.exists(model_engine_path):\n",
    "    print(f\"[INFO] Found '{model_engine_path}'. Loading TensorRT Engine...\")\n",
    "    try:\n",
    "        model = YOLO(model_engine_path, task='pose')\n",
    "        print(\"[SUCCESS] TensorRT Engine loaded correctly.\")\n",
    "        model_loaded = True\n",
    "        run_device = 0\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Error loading Engine: {e}. Switching to fallback...\")\n",
    "\n",
    "# 2. Try to load PT (Fallback)\n",
    "if not model_loaded:\n",
    "    print(f\"[INFO] Loading standard model '{model_pt_path}'...\")\n",
    "    try:\n",
    "        model = YOLO(model_pt_path)\n",
    "        if has_gpu:\n",
    "            run_device = 0\n",
    "            print(\"[SUCCESS] Model .pt loaded on GPU.\")\n",
    "        else:\n",
    "            run_device = 'cpu'\n",
    "            print(\"[SUCCESS] Model .pt loaded on CPU (Expect lower FPS).\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Critical: Could not load '{model_pt_path}'. {e}\")\n",
    "        sys.exit()\n",
    "\n",
    "# PERFORMANCE SETTINGS\n",
    "# -----------------------------------------\n",
    "TARGET_WIDTH = 1280    \n",
    "SKIP_YOLO_FRAMES = 3   \n",
    "IMG_SIZE = 640         \n",
    "# -----------------------------------------\n",
    "\n",
    "# COLOR MASKS (BALL)\n",
    "green_lower = np.array([37, 61, 100])\n",
    "green_upper = np.array([54, 138, 226])\n",
    "\n",
    "# BACKGROUND SUBTRACTION\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "# TRACKERS\n",
    "tracker = KalmanTracker() \n",
    "visual_trail = deque(maxlen=20) \n",
    "frames_without_detection = 0    \n",
    "MAX_MISSED_FRAMES = 10    \n",
    "history_buffer = deque(maxlen=15) \n",
    "\n",
    "# OPTICAL FLOW PARAMS\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "p0 = None      \n",
    "old_gray = None \n",
    "\n",
    "# PHYSICS & HIT LOGIC\n",
    "prev_ball_x = None; prev_ball_y = None; prev_velocity = 0\n",
    "hit_cooldown = 0; HIT_THRESHOLD = 8 \n",
    "HORIZONTAL_THRESHOLD = 12  \n",
    "FLOW_THRESHOLD = 5 \n",
    "\n",
    "# UI & STATE VARIABLES\n",
    "snapshot_frame = None; showing_snapshot_timer = 0\n",
    "bounce_state = 0; min_y_registered = 0; frames_verifying = 0; bounce_text_timer = 0\n",
    "\n",
    "# GENERAL\n",
    "frame_count = 0\n",
    "cached_waist_y = None; cached_ground_y = None; cached_zone_mask = None\n",
    "player_detected = False\n",
    "prev_frame_time = 0\n",
    "\n",
    "if not os.path.exists('serve_evidence'): os.makedirs('serve_evidence')\n",
    "save_counter = 0\n",
    "\n",
    "# ==========================================\n",
    "# 4. PLAYER ZONE LOGIC\n",
    "# ==========================================\n",
    "def get_player_zone(results, shape_img): \n",
    "    h, w = shape_img[:2]\n",
    "    zone_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    waist_y = None; ground_y = None\n",
    "    \n",
    "    if not results or len(results) == 0: return zone_mask, None, None, None\n",
    "    if not hasattr(results[0], 'keypoints') or results[0].keypoints is None: return zone_mask, None, None, None\n",
    "    \n",
    "    if results[0].keypoints.xy.numel() == 0: return zone_mask, None, None, None\n",
    "    points = results[0].keypoints.xy[0].cpu().numpy() \n",
    "    \n",
    "    if len(points) < 17: return zone_mask, None, None, None\n",
    "    valid_points = points[np.all(points > 0, axis=1)]\n",
    "\n",
    "    if len(valid_points) > 0:\n",
    "        hips = []\n",
    "        if points[11][1] > 0: hips.append(points[11][1])\n",
    "        if points[12][1] > 0: hips.append(points[12][1])\n",
    "        if len(hips) > 0: waist_y = int(sum(hips) / len(hips))\n",
    "        \n",
    "        feet = []\n",
    "        if points[15][1] > 0: feet.append(points[15][1])\n",
    "        if points[16][1] > 0: feet.append(points[16][1])\n",
    "        if len(feet) > 0: ground_y = int(max(feet) - 20) \n",
    "        elif waist_y: ground_y = int(waist_y * 1.6)\n",
    "        \n",
    "        min_y, max_y = np.min(valid_points[:, 1]), np.max(valid_points[:, 1])\n",
    "        min_x, max_x = np.min(valid_points[:, 0]), np.max(valid_points[:, 0])\n",
    "        cx = int((min_x + max_x) / 2)\n",
    "        cy = int((min_y + max_y) / 2)\n",
    "        radius = int((max_y - min_y) * 1.2) if (max_y - min_y) > 0 else 100\n",
    "        \n",
    "        cv2.circle(zone_mask, (cx, cy), radius, 255, -1)\n",
    "        return zone_mask, (cx, cy, radius), waist_y, ground_y\n",
    "    \n",
    "    return zone_mask, None, None, None\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION LOOP\n",
    "# ==========================================\n",
    "print(f\"[INFO] RESIZE ON ({TARGET_WIDTH}px). TensorRT Skip={SKIP_YOLO_FRAMES}.\")\n",
    "\n",
    "# Initialize Optical Flow grayscale\n",
    "ret, first_frame = cap.read()\n",
    "if ret:\n",
    "    h_raw, w_raw = first_frame.shape[:2]\n",
    "    new_h = int(TARGET_WIDTH / (w_raw / h_raw))\n",
    "    first_frame_resized = cv2.resize(first_frame, (TARGET_WIDTH, new_h))\n",
    "    old_gray = cv2.cvtColor(first_frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    sys.exit(\"[ERROR] Could not read first frame.\")\n",
    "\n",
    "while True:\n",
    "    if is_live:\n",
    "        ret, frame_raw = cap.read()\n",
    "    else:\n",
    "        ret, frame_raw = cap.read()\n",
    "        if not ret: \n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            prev_ball_x = None; prev_ball_y = None; prev_velocity = 0\n",
    "            visual_trail.clear(); history_buffer.clear(); tracker = KalmanTracker()\n",
    "            p0 = None \n",
    "            continue\n",
    "\n",
    "    if frame_raw is None: continue \n",
    "\n",
    "    # --- PRE-PROCESSING ---\n",
    "    h_raw, w_raw = frame_raw.shape[:2]\n",
    "    aspect_ratio = w_raw / h_raw\n",
    "    new_h = int(TARGET_WIDTH / aspect_ratio)\n",
    "    frame = cv2.resize(frame_raw, (TARGET_WIDTH, new_h))\n",
    "    \n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    frame_count += 1\n",
    "    display_frame = frame.copy()\n",
    "    h_curr, w_curr = frame.shape[:2]\n",
    "\n",
    "    # FPS CALCULATION\n",
    "    new_frame_time = time.time()\n",
    "    fps = 1 / (new_frame_time - prev_frame_time) if (new_frame_time - prev_frame_time) > 0 else 0\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(display_frame, f\"FPS: {int(fps)}\", (w_curr - 200, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # 1. PLAYER DETECTION (With Frame Skipping)\n",
    "    if frame_count % SKIP_YOLO_FRAMES == 0:\n",
    "        try:\n",
    "            results = model(frame, device=run_device, conf=0.5, max_det=1, verbose=False)\n",
    "            cached_zone_mask, _, cached_waist_y, cached_ground_y = get_player_zone(results, frame.shape)\n",
    "            player_detected = (cached_ground_y is not None)\n",
    "        except Exception:\n",
    "            player_detected = False\n",
    "    \n",
    "    if cached_zone_mask is None or cached_zone_mask.shape[:2] != (h_curr, w_curr):\n",
    "        cached_zone_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    waist_y = cached_waist_y\n",
    "    ground_y = cached_ground_y\n",
    "    zone_mask = cached_zone_mask\n",
    "\n",
    "    # 2. BALL DETECTION (Color + MOG2 + Morphology)\n",
    "    frame_blur = cv2.GaussianBlur(frame, (5, 5), 0)\n",
    "    hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "    mask_color = cv2.inRange(hsv, green_lower, green_upper)\n",
    "    mask_mov = fgbg.apply(frame_blur)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask_mov = cv2.morphologyEx(mask_mov, cv2.MORPH_OPEN, kernel)\n",
    "    mask_mov = cv2.dilate(mask_mov, kernel, iterations=2)\n",
    "    \n",
    "    potential_ball = cv2.bitwise_and(mask_color, mask_color, mask=mask_mov)\n",
    "    mask_final = cv2.bitwise_and(potential_ball, potential_ball, mask=zone_mask)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask_final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    curr_ball_y = None; cx_ball = 0; max_area = 0; ball_detected_this_frame = False \n",
    "\n",
    "    # Kalman Prediction\n",
    "    raw_pred_x, raw_pred_y = tracker.predict()\n",
    "    pred_x, pred_y = int(raw_pred_x), int(raw_pred_y)\n",
    "\n",
    "    # Contour Analysis\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 40: \n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w) / h\n",
    "            if 0.5 < aspect_ratio < 1.5: \n",
    "                if area > max_area:\n",
    "                    max_area = area; curr_ball_y = y + h//2; cx_ball = x + w//2\n",
    "                    ball_detected_this_frame = True\n",
    "                    tracker.correct(cx_ball, curr_ball_y)\n",
    "\n",
    "    # 3. HYBRID TRACKING (Optical Flow + Kalman)\n",
    "    new_flow_point = None\n",
    "    flow_velocity = 0 \n",
    "    \n",
    "    if p0 is not None:\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "        if p1 is not None and st[0] == 1:\n",
    "            new_flow_point = p1\n",
    "            fx, fy = p0[0].ravel()\n",
    "            nx, ny = p1[0].ravel()\n",
    "            flow_velocity = np.sqrt((nx - fx)**2 + (ny - fy)**2) \n",
    "        else:\n",
    "            new_flow_point = None\n",
    "\n",
    "    curr_x = pred_x; curr_y = pred_y \n",
    "\n",
    "    if ball_detected_this_frame:\n",
    "        frames_without_detection = 0\n",
    "        curr_x, curr_y = cx_ball, curr_ball_y\n",
    "        p0 = np.array([[[cx_ball, curr_ball_y]]], dtype=np.float32)\n",
    "        visual_trail.append((cx_ball, curr_ball_y))\n",
    "    \n",
    "    elif new_flow_point is not None and frames_without_detection < MAX_MISSED_FRAMES:\n",
    "        frames_without_detection += 1\n",
    "        flow_x, flow_y = new_flow_point[0].ravel()\n",
    "        p0 = new_flow_point.reshape(-1, 1, 2)\n",
    "        visual_trail.append((int(flow_x), int(flow_y)))\n",
    "    else:\n",
    "        frames_without_detection += 1\n",
    "        if frames_without_detection >= MAX_MISSED_FRAMES:\n",
    "            curr_ball_y = None; visual_trail.clear(); curr_x, curr_y = None, None\n",
    "            prev_velocity = 0; prev_ball_x = None; p0 = None\n",
    "    \n",
    "    history_buffer.append((frame.copy(), curr_x, curr_y, waist_y))\n",
    "\n",
    "    # --- VISUALS: DRAW TRAIL & BOX ---\n",
    "    for i in range(1, len(visual_trail)):\n",
    "        if visual_trail[i - 1] and visual_trail[i]:\n",
    "            thickness = int(np.sqrt(20 / float(len(visual_trail) - i + 1)) * 2)\n",
    "            cv2.line(display_frame, visual_trail[i - 1], visual_trail[i], (0, 255, 255), thickness)\n",
    "\n",
    "    if curr_x is not None and curr_y is not None:\n",
    "        box_radius = 15\n",
    "        top_left = (int(curr_x - box_radius), int(curr_y - box_radius))\n",
    "        bottom_right = (int(curr_x + box_radius), int(curr_y + box_radius))\n",
    "        cv2.rectangle(display_frame, top_left, bottom_right, (0, 255, 0), 2)\n",
    "        cv2.putText(display_frame, \"BALL\", (int(curr_x - 20), int(curr_y - 25)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # --- 4. HIT LOGIC ---\n",
    "    acceleration = 0\n",
    "    if 'prev_ball_x' not in locals(): prev_ball_x = None\n",
    "\n",
    "    if curr_x is not None and prev_ball_y is not None and prev_ball_x is not None:\n",
    "        dx = curr_x - prev_ball_x; dy = curr_y - prev_ball_y \n",
    "        curr_velocity = np.sqrt(dx**2 + dy**2)\n",
    "        acceleration = curr_velocity - prev_velocity\n",
    "        \n",
    "        is_hard_hit = acceleration > HIT_THRESHOLD\n",
    "        is_visual_motion = flow_velocity > FLOW_THRESHOLD\n",
    "\n",
    "        if is_hard_hit and is_visual_motion and hit_cooldown == 0:\n",
    "            if waist_y and abs(curr_y - waist_y) < 180: \n",
    "                going_down = dy > 2; is_very_vertical = (abs(dx) < HORIZONTAL_THRESHOLD) \n",
    "                \n",
    "                if not (going_down or is_very_vertical):\n",
    "                    hit_cooldown = 15 \n",
    "                    print(f\"SERVE DETECTED >> Kalman Accel: {acceleration:.1f} | Flow Vel: {flow_velocity:.1f}\")\n",
    "\n",
    "                    # --- PHOTO FINISH ---\n",
    "                    retro_idx = -3\n",
    "                    if len(history_buffer) >= abs(retro_idx):\n",
    "                        hist_frame, hist_x, hist_y, hist_waist = history_buffer[retro_idx]\n",
    "                        if hist_x and hist_y and hist_waist:\n",
    "                            snapshot_frame = hist_frame.copy()\n",
    "                            \n",
    "                            # Determine Verdict and Color\n",
    "                            vertical_dist = hist_y - hist_waist\n",
    "                            label = \"VALID\" if vertical_dist > 0 else \"FAULT\"\n",
    "                            col = (0,255,0) if vertical_dist > 0 else (0,0,255)\n",
    "\n",
    "                            # 1. Waist Line\n",
    "                            cv2.line(snapshot_frame, (0, hist_waist), (w_curr, hist_waist), (0, 255, 255), 2)\n",
    "                            \n",
    "                            # 2. Ball Circle\n",
    "                            cv2.circle(snapshot_frame, (hist_x, hist_y), 25, (255, 255, 0), 3)\n",
    "                            \n",
    "                            # 3. VERTICAL LINE (Visual Evidence)\n",
    "                            # Connects ball center to waist line height\n",
    "                            cv2.line(snapshot_frame, (hist_x, hist_y), (hist_x, hist_waist), col, 2)\n",
    "                            \n",
    "                            cv2.putText(snapshot_frame, f\"{label}\", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.2, col, 3)\n",
    "                            \n",
    "                            showing_snapshot_timer = 90 \n",
    "                            save_counter += 1\n",
    "                            cv2.imwrite(f\"serve_evidence/serve_{save_counter}.jpg\", snapshot_frame)\n",
    "\n",
    "        prev_velocity = curr_velocity; prev_ball_x = curr_x \n",
    "    else:\n",
    "        prev_velocity = 0; prev_ball_x = curr_x\n",
    "\n",
    "    if hit_cooldown > 0: hit_cooldown -= 1\n",
    "\n",
    "    # --- 5. BOUNCE LOGIC ---\n",
    "    if curr_y is not None and ground_y is not None and player_detected:\n",
    "        if bounce_state == 0:\n",
    "            if prev_ball_y and prev_ball_y < ground_y and curr_y >= ground_y:\n",
    "                bounce_state = 1; min_y_registered = curr_y; frames_verifying = 0\n",
    "        elif bounce_state == 1:\n",
    "            frames_verifying += 1\n",
    "            if curr_y > min_y_registered: min_y_registered = curr_y\n",
    "            if curr_y < (min_y_registered - 15): \n",
    "                bounce_text_timer = 30; bounce_state = 0 \n",
    "            if frames_verifying > 20: bounce_state = 0\n",
    "\n",
    "    if curr_y: prev_ball_y = curr_y\n",
    "\n",
    "    # --- FINAL DRAWING ---\n",
    "    if player_detected:\n",
    "        if waist_y: cv2.line(display_frame, (0, waist_y), (w_curr, waist_y), (0, 255, 255), 2)\n",
    "        if ground_y: cv2.line(display_frame, (0, ground_y), (w_curr, ground_y), (0, 255, 0), 2)\n",
    "    \n",
    "    if bounce_text_timer > 0:\n",
    "         cv2.putText(display_frame, \"BOUNCE\", (int(w_curr/2)-100, int(h_curr/2)), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 3)\n",
    "         bounce_text_timer -= 1\n",
    "\n",
    "    if showing_snapshot_timer > 0 and snapshot_frame is not None:\n",
    "        cv2.imshow(\"SERVE DETECTOR - PHOTO FINISH\", snapshot_frame)\n",
    "        showing_snapshot_timer -= 1\n",
    "    else:\n",
    "        try: cv2.destroyWindow(\"SERVE DETECTOR - PHOTO FINISH\")\n",
    "        except: pass\n",
    "\n",
    "    mask_bgr = cv2.cvtColor(mask_final, cv2.COLOR_GRAY2BGR)\n",
    "    dual_view = np.hstack([display_frame, mask_bgr])\n",
    "    \n",
    "    cv2.imshow('PADEL SERVE DETECTOR v3.0', dual_view)\n",
    "    \n",
    "    old_gray = frame_gray.copy()\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
    "\n",
    "if is_live: cap.stop()\n",
    "else: cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
